{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup"
   },
   "outputs": [],
   "source": [
    "!pip install python-telegram-bot aiohttp pyngrok\n",
    "!git clone https://github.com/dhaneshsaini/Fooocus.git\n",
    "%cd /content/Fooocus\n",
    "!pip install -r requirements_versions.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "runfooocus"
   },
   "outputs": [],
   "source": [
    "# Run Fooocus in API mode\n",
    "!python entry_with_update.py --share --always-high-vram --listen --api --port 7865 &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ngrok"
   },
   "outputs": [],
   "source": [
    "from pyngrok import ngrok\n",
    "\n",
    "# Start ngrok tunnel to port 7865\n",
    "public_url = ngrok.connect(7865)\n",
    "print(\"Fooocus API URL:\", public_url)\n",
    "\n",
    "# Save this URL for the bot\n",
    "FOOOCUS_API = str(public_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "telegrambot"
   },
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import io\n",
    "import base64\n",
    "from telegram import Update\n",
    "from telegram.ext import Application, CommandHandler, ContextTypes\n",
    "\n",
    "# Your Telegram bot token\n",
    "TOKEN = \"8079802285:AAGHjLH6VFBGl2ulzHR4OloAhIuFCmObbv0\"\n",
    "\n",
    "# --- Fetch all LoRAs ---\n",
    "async def get_loras():\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(f\"{FOOOCUS_API}/sdapi/v1/loras\") as resp:\n",
    "            data = await resp.json()\n",
    "            return {l[\"name\"]: l for l in data}\n",
    "\n",
    "# --- Generate Image ---\n",
    "async def generate_image(prompt, negative, loras_payload):\n",
    "    payload = {\n",
    "        \"prompt\": prompt,\n",
    "        \"negative_prompt\": negative,\n",
    "        \"loras\": loras_payload,\n",
    "        \"width\": 512,\n",
    "        \"height\": 512,\n",
    "        \"steps\": 25\n",
    "    }\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(f\"{FOOOCUS_API}/sdapi/v1/txt2img\", json=payload) as resp:\n",
    "            data = await resp.json()\n",
    "            img_data = base64.b64decode(data[\"images\"][0])\n",
    "            return io.BytesIO(img_data)\n",
    "\n",
    "# --- /generate ---\n",
    "async def generate(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "    try:\n",
    "        if not context.args:\n",
    "            await update.message.reply_text(\"‚ö†Ô∏è Usage: /generate <prompt> | <negative> | <Lora:val,...>\")\n",
    "            return\n",
    "\n",
    "        parts = \" \".join(context.args).split(\"|\")\n",
    "        prompt = parts[0].strip()\n",
    "        negative = parts[1].strip() if len(parts) > 1 else \"ugly, blurry\"\n",
    "        lora_str = parts[2].strip() if len(parts) > 2 else \"\"\n",
    "\n",
    "        all_loras = await get_loras()\n",
    "        chosen_loras = []\n",
    "        if lora_str:\n",
    "            for item in lora_str.split(\",\"):\n",
    "                if \":\" in item:\n",
    "                    name, val = item.split(\":\")\n",
    "                    name, val = name.strip(), float(val.strip())\n",
    "                    if name in all_loras:\n",
    "                        chosen_loras.append({\"name\": name, \"value\": val})\n",
    "\n",
    "        img_bytes = await generate_image(prompt, negative, chosen_loras)\n",
    "\n",
    "        await update.message.reply_photo(\n",
    "            photo=img_bytes,\n",
    "            caption=f\"‚úÖ Prompt: `{prompt}`\\nüìâ Negative: `{negative}`\\nüé® LoRAs: {chosen_loras}\",\n",
    "            parse_mode=\"Markdown\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        await update.message.reply_text(f\"‚ö†Ô∏è Error: {e}\")\n",
    "\n",
    "# --- /loras ---\n",
    "async def loras(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "    try:\n",
    "        all_loras = await get_loras()\n",
    "        msg = \"**üé® Available LoRAs:**\\n\"\n",
    "        for name in all_loras.keys():\n",
    "            msg += f\"- `{name}`\\n\"\n",
    "        await update.message.reply_text(msg, parse_mode=\"Markdown\")\n",
    "    except Exception as e:\n",
    "        await update.message.reply_text(f\"‚ö†Ô∏è Error fetching LoRAs: {e}\")\n",
    "\n",
    "# --- /help ---\n",
    "async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "    help_text = (\n",
    "        \"ü§ñ *Fooocus Bot Commands:*\\n\\n\"\n",
    "        \"/generate <prompt> | <negative> | <Lora:val,...>\\n\"\n",
    "        \" Example: `/generate a cyberpunk girl | blurry | RealSkin:0.7,AnimeStyle:0.9`\\n\\n\"\n",
    "        \"/loras - List all available LoRAs\\n\"\n",
    "        \"/help - Show this help message\"\n",
    "    )\n",
    "    await update.message.reply_text(help_text, parse_mode=\"Markdown\")\n",
    "\n",
    "# --- Run ---\n",
    "def main():\n",
    "    app = Application.builder().token(TOKEN).build()\n",
    "    app.add_handler(CommandHandler(\"generate\", generate))\n",
    "    app.add_handler(CommandHandler(\"loras\", loras))\n",
    "    app.add_handler(CommandHandler(\"help\", help_cmd))\n",
    "    app.run_polling()\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
